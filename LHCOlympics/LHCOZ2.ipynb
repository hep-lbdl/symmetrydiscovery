{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Lambda, Layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_hdf(\"events_anomalydetection_DelphesPythia8_v2_qcd_features.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = (f[['pxj1','pxj2', 'pyj1', 'pyj2']]).to_numpy()\n",
    "px1 = G[:, 0]\n",
    "py1 = G[:, 2]\n",
    "px2 = G[:, 1]\n",
    "py2 = G[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self._t1 = self.add_weight(name='x', \n",
    "                                    #shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.RandomUniform(minval= 0, maxval=2*np.pi), #'uniform',\n",
    "                                    trainable=True)\n",
    "        self._t2 = self.add_weight(name='x', \n",
    "                                    #shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=2*np.pi), #'uniform',\n",
    "                                    trainable=True)\n",
    "        self._t3 = self.add_weight(name='x', \n",
    "                                    #shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=2*np.pi), #'uniform',\n",
    "                                    trainable=True)\n",
    "        self._t4 = self.add_weight(name='x', \n",
    "                                    #shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=2*np.pi), #'uniform',\n",
    "                                    trainable=True)\n",
    "        self._t5 = self.add_weight(name='x', \n",
    "                                    #shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=2*np.pi), #'uniform',\n",
    "                                    trainable=True)\n",
    "        self._t6 = self.add_weight(name='x', \n",
    "                                    #shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=2*np.pi), #'uniform',\n",
    "                                    trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        s1 = tf.math.sin(self._t1)\n",
    "        c1 = tf.math.cos(self._t1)\n",
    "        s2 = tf.math.sin(self._t2)\n",
    "        c2 = tf.math.cos(self._t2)\n",
    "        s3 = tf.math.sin(self._t3)\n",
    "        c3 = tf.math.cos(self._t3)\n",
    "        s4 = tf.math.sin(self._t4)\n",
    "        c4 = tf.math.cos(self._t4)\n",
    "        s5 = tf.math.sin(self._t5)\n",
    "        c5 = tf.math.cos(self._t5)\n",
    "        s6 = tf.math.sin(self._t6)\n",
    "        c6 = tf.math.cos(self._t6)\n",
    "        R1 = [[c1, s1, 0.0, 0.0], [-1.0*s1, c1, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]] #px1 -> py1     \n",
    "        R2 = [[c2, 0.0, s2, 0.0], [0.0, 1.0, 0.0, 0.0], [-1.0*s2, 0.0, c2, 0.0], [0.0, 0.0, 0.0, 1.0]] #px1 -> px2\n",
    "        R3 = [[c3, 0.0, 0.0, s3], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [-1.0*s3, 0.0, 0.0, c3]] #px1 -> py2\n",
    "        R4 = [[1.0, 0.0, 0.0, 0.0], [0.0, c4, s4, 0.0], [0.0, -1.0*s4, c4, 0.0], [0.0, 0.0, 0.0, 1.0]] #px2 -> py1\n",
    "        R5 = [[1.0, 0.0, 0.0, 0.0], [0.0, c5, 0.0, s5], [0.0, 0.0, 1.0, 0.0], [0.0, -1.0*s5, 0.0, c5]] #px2 -> py1\n",
    "        R6 = [[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, c6, s6], [0.0, 0.0, -1.0*s6, c6]] #py1 -> py2\n",
    "        S = tf.linalg.matmul(R1, tf.linalg.matmul(R2, (tf.linalg.matmul(R3, tf.linalg.matmul(R4, tf.linalg.matmul(R5, R6))))))\n",
    "        #S = R1 @ R2 @ R3 @ R4 @ R5 @ R6\n",
    "        M = tf.convert_to_tensor(S)\n",
    "        M = tf.reshape(M, [4, 4])\n",
    "        return tf.linalg.matmul(X, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss2d(y_true, y_pred, alpha = 0.1):\n",
    "    #alpha determines the amount of decorrelation; 0 means no decorrelation.\n",
    "    \n",
    "    #We want to learn g(g(x)) = x with g != identity and g(x) and x should have the same probability density.\n",
    "    #x = y_pred[:,0]\n",
    "    #g(g(x)) = y_pred[:,1]\n",
    "    #h(g(x)) = y_pred[:,2]\n",
    "\n",
    "    return binary_crossentropy(y_pred[:,8], y_true) + alpha*mse(y_pred[:,0:4],y_pred[:,4:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(n_inputs=4):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))    \n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(n_outputs=1):\n",
    "\t#model = Sequential()\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))    \n",
    "\t#model.add(Dense(n_outputs, activation='linear'))\n",
    "\n",
    "\tmymodel_inputtest = Input(shape=(4,))\n",
    "\tmymodel_test = MyLayer()(mymodel_inputtest)\n",
    "\tmodel = Model(mymodel_inputtest, mymodel_test)\n",
    "\treturn model\n",
    " \n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    myinput_2d = Input(shape=(4,))\n",
    "    encoded_2d = generator(myinput_2d)\n",
    "    myidentity = Lambda(lambda x: x)(myinput_2d)\n",
    "    encoder_2d = Model(myinput_2d, encoded_2d)\n",
    "    encoder2_2d = encoder_2d(encoder_2d((myinput_2d)))\n",
    "    autoencoder_2d = Model(myinput_2d, encoder2_2d)\n",
    "    \n",
    "    discriminated_2d = discriminator(myinput_2d)\n",
    "    discriminator_2d = Model(myinput_2d, discriminated_2d)\n",
    "    discriminator2_2d = discriminator_2d(encoder_2d(myinput_2d))\n",
    "    model_discriminator2_2d = Model(myinput_2d, discriminator2_2d)\n",
    "    \n",
    "    justinput = Model(myinput_2d, myidentity)\n",
    "    combinedModel_2d = Model(myinput_2d,Concatenate(axis=-1)([myidentity, encoder2_2d, discriminator2_2d]))\n",
    "    \n",
    "    # compile model\n",
    "    combinedModel_2d.compile(loss=lambda y_true, y_pred: myloss2d(y_true, y_pred), optimizer='adam')\n",
    "    return combinedModel_2d\n",
    " \n",
    "# generate n real samples with class labels\n",
    "def generate_real_samples(n):\n",
    "\trandomlySelectedY = np.argsort(np.random.random(len(px1)))[:n]\n",
    "\tX = tf.convert_to_tensor([px1[randomlySelectedY], py1[randomlySelectedY], px2[randomlySelectedY], py2[randomlySelectedY]])\n",
    "\ty = np.ones((n, 1))\n",
    "\treturn np.transpose(X), y\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(n):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = generate_real_samples(n)\n",
    "\treturn x_input[0]\n",
    " \n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = np.zeros((n, 1))\n",
    "\treturn X, y\n",
    "\n",
    "def generate_fake_samples_with_input(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = np.zeros((n, 1))\n",
    "\treturn X, y, x_input\n",
    "\n",
    "k = 1000\n",
    " \n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, n_epochs=5*k, n_batch=128, n_eval=k):\n",
    "\t# determine half the size of one batch, for updating the discriminator\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# prepare real samples\n",
    "\t\tx_real, y_real = generate_real_samples(half_batch)\n",
    "\t\t# prepare fake examples\n",
    "\t\tx_fake, y_fake = generate_fake_samples(g_model, half_batch)\n",
    "\t\t# update discriminator\n",
    "\t\td_model.train_on_batch(x_real, y_real)\n",
    "\t\td_model.train_on_batch(x_fake, y_fake)\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tx_gan = generate_latent_points(n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = np.ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\tgan_model.train_on_batch(x_gan, y_gan)\n",
    "\t\tif (i+1) % n_eval == 0:\n",
    "\t\t\tprint(\"epoch = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7824d804ab91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mt1f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mt2f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8d97a3d8541c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, n_epochs, n_batch, n_eval)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mx_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;31m# prepare fake examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0;31m# update discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8d97a3d8541c>\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[0;34m(generator, n)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# generate points in latent space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;31m# predict outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8d97a3d8541c>\u001b[0m in \u001b[0;36mgenerate_latent_points\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# generate points in the latent space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8d97a3d8541c>\u001b[0m in \u001b[0;36mgenerate_real_samples\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# generate n real samples with class labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mrandomlySelectedY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandomlySelectedY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandomlySelectedY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandomlySelectedY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandomlySelectedY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \"\"\"\n\u001b[0;32m-> 1114\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "t1i = []\n",
    "t1f = []\n",
    "t2i = []\n",
    "t2f = []\n",
    "t3i = []\n",
    "t3f = []\n",
    "t4i = []\n",
    "t4f = []\n",
    "t5i = []\n",
    "t5f = []\n",
    "t6i = []\n",
    "t6f = []\n",
    "for j in range(N):\n",
    "    print(\"j = \", j)\n",
    "    # create the discriminator\n",
    "    discriminator = define_discriminator()\n",
    "    # create the generator\n",
    "    generator = define_generator()\n",
    "    # create the gan\n",
    "    gan_model = define_gan(generator, discriminator)\n",
    "    t1i.append(generator.layers[-1].get_weights()[0])\n",
    "    t2i.append(generator.layers[-1].get_weights()[1])\n",
    "    t3i.append(generator.layers[-1].get_weights()[2])\n",
    "    t4i.append(generator.layers[-1].get_weights()[3])\n",
    "    t5i.append(generator.layers[-1].get_weights()[4])\n",
    "    t6i.append(generator.layers[-1].get_weights()[5])\n",
    "\n",
    "    # train model\n",
    "    train(generator, discriminator, gan_model)\n",
    "    t1f.append(generator.layers[-1].get_weights()[0])\n",
    "    t2f.append(generator.layers[-1].get_weights()[1])\n",
    "    t3f.append(generator.layers[-1].get_weights()[2])\n",
    "    t4f.append(generator.layers[-1].get_weights()[3])\n",
    "    t5f.append(generator.layers[-1].get_weights()[4])\n",
    "    t6f.append(generator.layers[-1].get_weights()[5])\n",
    "    print(\"t1i = \", t1i)\n",
    "    print(\"t2i = \", t2i)\n",
    "    print(\"t3i = \", t3i)\n",
    "    print(\"t4i = \", t4i)\n",
    "    print(\"t5i = \", t5i)\n",
    "    print(\"t6i = \", t6i)\n",
    "    print(\"t1f = \", t1f)\n",
    "    print(\"t2f = \", t2f)\n",
    "    print(\"t3f = \", t3f)\n",
    "    print(\"t4f = \", t4f) \n",
    "    print(\"t5f = \", t5f)\n",
    "    print(\"t6f = \", t6f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
