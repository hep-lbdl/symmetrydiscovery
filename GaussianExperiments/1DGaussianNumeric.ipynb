{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Lambda, Dense, Input, Layer, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "initializer = tf.keras.initializers.RandomUniform(minval=-5., maxval=5.)\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self._c = self.add_weight(name='x', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=initializer, #'uniform',\n",
    "                                    trainable=True)\n",
    "        self._b = self.add_weight(name='x', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=initializer, #'uniform',\n",
    "                                    trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return self._b + self._c*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick vanilla GAN from https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/\n",
    " \n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(n_inputs=1):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))    \n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(n_outputs=1):\n",
    "\t#model = Sequential()\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))    \n",
    "\t#model.add(Dense(n_outputs, activation='linear'))\n",
    "\n",
    "\tmymodel_inputtest = Input(shape=(1,))\n",
    "\tmymodel_test = MyLayer()(mymodel_inputtest)\n",
    "\tmodel = Model(mymodel_inputtest, mymodel_test)\n",
    "\treturn model\n",
    " \n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tdiscriminator.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(discriminator)\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\treturn model\n",
    " \n",
    "# generate n real samples with class labels\n",
    "def generate_real_samples(n):\n",
    "\tX = np.random.normal(0.5,1,n)\n",
    "\ty = ones((n, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(n):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = generate_real_samples(n)\n",
    "\treturn x_input[0]\n",
    " \n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n, 1))\n",
    "\treturn X, y\n",
    "\n",
    "def generate_fake_samples_with_input(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n, 1))\n",
    "\treturn X, y, x_input\n",
    " \n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, n_epochs=10000, n_batch=128, n_eval=2000):\n",
    "\t# determine half the size of one batch, for updating the discriminator\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# prepare real samples\n",
    "\t\tx_real, y_real = generate_real_samples(half_batch)\n",
    "\t\t# prepare fake examples\n",
    "\t\tx_fake, y_fake = generate_fake_samples(g_model, half_batch)\n",
    "\t\t# update discriminator\n",
    "\t\td_model.train_on_batch(x_real, y_real)\n",
    "\t\td_model.train_on_batch(x_fake, y_fake)\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tx_gan = generate_latent_points(n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\tgan_model.train_on_batch(x_gan, y_gan)\n",
    "\t\tif (i+1) % n_eval == 0:\n",
    "\t\t\tprint(\"epoch = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  0\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65]\n",
      "[-0.04]\n",
      "[3.15]\n",
      "[0.99]\n",
      "j =  1\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51]\n",
      "[-0.04, 0.0]\n",
      "[3.15, 4.25]\n",
      "[0.99, 1.04]\n",
      "j =  2\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14]\n",
      "[-0.04, 0.0, 0.01]\n",
      "[3.15, 4.25, 3.95]\n",
      "[0.99, 1.04, 0.98]\n",
      "j =  3\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34]\n",
      "[-0.04, 0.0, 0.01, 1.06]\n",
      "[3.15, 4.25, 3.95, -3.9]\n",
      "[0.99, 1.04, 0.98, -1.0]\n",
      "j =  4\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97]\n",
      "j =  5\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97]\n",
      "j =  6\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01]\n",
      "j =  7\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96]\n",
      "j =  8\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0]\n",
      "j =  9\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94]\n",
      "j =  10\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93]\n",
      "j =  11\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03]\n",
      "j =  12\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18, 4.65]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01, -0.01]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9, 3.15]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03, 1.04]\n",
      "j =  13\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18, 4.65, 0.21]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01, -0.01, -0.01]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9, 3.15, 3.09]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03, 1.04, 0.99]\n",
      "j =  14\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18, 4.65, 0.21, 3.45]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01, -0.01, -0.01, -0.05]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9, 3.15, 3.09, 3.84]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03, 1.04, 0.99, 1.02]\n",
      "j =  15\n",
      "epoch =  1999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2974fc6176de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mc_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mb_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mc_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bb75e9c44b01>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, n_epochs, n_batch, n_eval)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# update discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;31m# prepare points in latent space as input for the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mx_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                                     class_weight)\n\u001b[1;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 20\n",
    "b_i = []\n",
    "c_i = []\n",
    "b_f = []\n",
    "c_f = []\n",
    "for j in range(N):\n",
    "    print(\"j = \", j)\n",
    "    # create the discriminator\n",
    "    discriminator = define_discriminator()\n",
    "    # create the generator\n",
    "    generator = define_generator()\n",
    "    # create the gan\n",
    "    gan_model = define_gan(generator, discriminator)\n",
    "    b_i.append(round(generator.layers[-1].get_weights()[1][0], 2))\n",
    "    c_i.append(round(generator.layers[-1].get_weights()[0][0], 2))\n",
    "    # train model\n",
    "    train(generator, discriminator, gan_model)\n",
    "    b_f.append(round(generator.layers[-1].get_weights()[1][0], 2))\n",
    "    c_f.append(round(generator.layers[-1].get_weights()[0][0], 2))\n",
    "    print(b_i)\n",
    "    print(b_f)\n",
    "    print(c_i)\n",
    "    print(c_f)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "b_i = [2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18, 4.65, 0.21, 3.45, 2.6, -4.2, 4.2, -0.4, 1.9, -3.7, 3.8, -1.1, 3.1, 1.3, 1.4, 2.2, 4.7, 0.3, 3.6]\n",
    "b_f = [-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01, -0.01, -0.01, -0.05, 0, 0,0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "c_i = [3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9, 3.15, 3.09, 3.84, 1.2, 4.4, 1.7, -1.3, 0, -1.2, -4.5, 0.2, 3.3, -2.7, -3.2, 2.7, 3.2, 3.1, 3.9]\n",
    "c_f = [0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03, 1.04, 0.99, 1.02, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('font', size=15)\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.xaxis.label.set_color('white')        #setting up X-axis label color to yellow\n",
    "ax.yaxis.label.set_color('white')          #setting up Y-axis label color to blue\n",
    "\n",
    "ax.tick_params(axis='x', colors='white')    #setting up X-axis tick color to red\n",
    "ax.tick_params(axis='y', colors='white')  #setting up Y-axis tick color to black\n",
    "\n",
    "ax.spines['left'].set_color('white')        # setting up Y-axis tick color to red\n",
    "ax.spines['top'].set_color('white')\n",
    "ax.spines['right'].set_color('white') \n",
    "ax.spines['bottom'].set_color('white') \n",
    "plt.scatter(c_i, c_f)\n",
    "plt.xlabel(r'$c_i$ (initial slope)', c='w')\n",
    "plt.ylabel(r'$c_f$ (final slope)', c='w')\n",
    "plt.savefig('c_ic_f.png',  bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-v2.2.0-cpu",
   "language": "python",
   "name": "tensorflow_intel_2.2.0-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
