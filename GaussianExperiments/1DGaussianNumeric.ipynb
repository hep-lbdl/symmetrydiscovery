{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Lambda, Dense, Input, Layer, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "initializer = tf.keras.initializers.RandomUniform(minval=-5., maxval=5.)\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self._c = self.add_weight(name='x', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=initializer, #'uniform',\n",
    "                                    trainable=True)\n",
    "        self._b = self.add_weight(name='x', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=initializer, #'uniform',\n",
    "                                    trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return self._b + self._c*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick vanilla GAN from https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/\n",
    " \n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(n_inputs=1):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))    \n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(n_outputs=1):\n",
    "\t#model = Sequential()\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))    \n",
    "\t#model.add(Dense(n_outputs, activation='linear'))\n",
    "\n",
    "\tmymodel_inputtest = Input(shape=(1,))\n",
    "\tmymodel_test = MyLayer()(mymodel_inputtest)\n",
    "\tmodel = Model(mymodel_inputtest, mymodel_test)\n",
    "\treturn model\n",
    " \n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tdiscriminator.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(discriminator)\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\treturn model\n",
    " \n",
    "# generate n real samples with class labels\n",
    "def generate_real_samples(n):\n",
    "\tX = np.random.normal(0.5,1,n)\n",
    "\ty = ones((n, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(n):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = generate_real_samples(n)\n",
    "\treturn x_input[0]\n",
    " \n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n, 1))\n",
    "\treturn X, y\n",
    "\n",
    "def generate_fake_samples_with_input(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n, 1))\n",
    "\treturn X, y, x_input\n",
    " \n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, n_epochs=10000, n_batch=128, n_eval=2000):\n",
    "\t# determine half the size of one batch, for updating the discriminator\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# prepare real samples\n",
    "\t\tx_real, y_real = generate_real_samples(half_batch)\n",
    "\t\t# prepare fake examples\n",
    "\t\tx_fake, y_fake = generate_fake_samples(g_model, half_batch)\n",
    "\t\t# update discriminator\n",
    "\t\td_model.train_on_batch(x_real, y_real)\n",
    "\t\td_model.train_on_batch(x_fake, y_fake)\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tx_gan = generate_latent_points(n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\tgan_model.train_on_batch(x_gan, y_gan)\n",
    "\t\tif (i+1) % n_eval == 0:\n",
    "\t\t\tprint(\"epoch = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  0\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65]\n",
      "[-0.04]\n",
      "[3.15]\n",
      "[0.99]\n",
      "j =  1\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51]\n",
      "[-0.04, 0.0]\n",
      "[3.15, 4.25]\n",
      "[0.99, 1.04]\n",
      "j =  2\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14]\n",
      "[-0.04, 0.0, 0.01]\n",
      "[3.15, 4.25, 3.95]\n",
      "[0.99, 1.04, 0.98]\n",
      "j =  3\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34]\n",
      "[-0.04, 0.0, 0.01, 1.06]\n",
      "[3.15, 4.25, 3.95, -3.9]\n",
      "[0.99, 1.04, 0.98, -1.0]\n",
      "j =  4\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97]\n",
      "j =  5\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97]\n",
      "j =  6\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01]\n",
      "j =  7\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96]\n",
      "j =  8\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0]\n",
      "j =  9\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94]\n",
      "j =  10\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93]\n",
      "j =  11\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03]\n",
      "j =  12\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18, 4.65]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01, -0.01]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9, 3.15]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03, 1.04]\n",
      "j =  13\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18, 4.65, 0.21]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01, -0.01, -0.01]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9, 3.15, 3.09]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03, 1.04, 0.99]\n",
      "j =  14\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "[2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18, 4.65, 0.21, 3.45]\n",
      "[-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01, -0.01, -0.01, -0.05]\n",
      "[3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9, 3.15, 3.09, 3.84]\n",
      "[0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03, 1.04, 0.99, 1.02]\n",
      "j =  15\n",
      "epoch =  1999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2974fc6176de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mc_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mb_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mc_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bb75e9c44b01>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, n_epochs, n_batch, n_eval)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# update discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;31m# prepare points in latent space as input for the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mx_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                                     class_weight)\n\u001b[1;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 20\n",
    "b_i = []\n",
    "c_i = []\n",
    "b_f = []\n",
    "c_f = []\n",
    "for j in range(N):\n",
    "    print(\"j = \", j)\n",
    "    # create the discriminator\n",
    "    discriminator = define_discriminator()\n",
    "    # create the generator\n",
    "    generator = define_generator()\n",
    "    # create the gan\n",
    "    gan_model = define_gan(generator, discriminator)\n",
    "    b_i.append(round(generator.layers[-1].get_weights()[1][0], 2))\n",
    "    c_i.append(round(generator.layers[-1].get_weights()[0][0], 2))\n",
    "    # train model\n",
    "    train(generator, discriminator, gan_model)\n",
    "    b_f.append(round(generator.layers[-1].get_weights()[1][0], 2))\n",
    "    c_f.append(round(generator.layers[-1].get_weights()[0][0], 2))\n",
    "    print(b_i)\n",
    "    print(b_f)\n",
    "    print(c_i)\n",
    "    print(c_f)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "b_i = [2.65, -4.51, 4.14, -0.34, 1.79, -3.93, 3.73, -1.08, 3.99, 1.28, 1.35, 2.18, 4.65, 0.21, 3.45, 2.6, -4.2, 4.2, -0.4, 1.9, -3.7, 3.8, -1.1, 3.1, 1.3, 1.4, 2.2, 4.7, 0.3, 3.6]\n",
    "b_f = [-0.04, 0.0, 0.01, 1.06, 1.01, 0.99, 1.02, -0.02, 0.0, 1.02, 0.98, -0.01, -0.01, -0.01, -0.05, 0, 0,0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "c_i = [3.15, 4.25, 3.95, -3.9, 0.09, -3.11, -4.49, 0.17, 3.25, -2.95, -3.17, 2.9, 3.15, 3.09, 3.84, 1.2, 4.4, 1.7, -1.3, 0, -1.2, -4.5, 0.2, 3.3, -2.7, -3.2, 2.7, 3.2, 3.1, 3.9]\n",
    "c_f = [0.99, 1.04, 0.98, -1.0, -0.97, -0.97, -1.01, 0.96, 1.0, -0.94, -0.93, 1.03, 1.04, 0.99, 1.02, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('font', size=15)\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# ax.xaxis.label.set_color('white')        #setting up X-axis label color to yellow\n",
    "# ax.yaxis.label.set_color('white')          #setting up Y-axis label color to blue\n",
    "\n",
    "# ax.tick_params(axis='x', colors='white')    #setting up X-axis tick color to red\n",
    "# ax.tick_params(axis='y', colors='white')  #setting up Y-axis tick color to black\n",
    "\n",
    "# ax.spines['left'].set_color('white')        # setting up Y-axis tick color to red\n",
    "# ax.spines['top'].set_color('white')\n",
    "# ax.spines['right'].set_color('white') \n",
    "# ax.spines['bottom'].set_color('white') \n",
    "plt.scatter(b_i, b_f, c='r')\n",
    "plt.xlabel(r'$b_i$ (initial intercept)'#, c='w'\n",
    "          )\n",
    "plt.ylabel(r'$b_f$ (final intercept)'#, c='w'\n",
    "          )\n",
    "plt.title(r\"$\\mathcal{N}(0.5, 1)$\")\n",
    "plt.savefig('b_ib_f.pdf',  bbox_inches='tight' #,transparent=True\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
